<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>Wan, Bo (万博)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=_7KkpE4AAAAJ&hl=en">Google Scholar</a></div>
<div class="menu-item"><a href="https://github.com/bobwan1995">GitHub</a></div>
<div class="menu-item"><a href="https://www.linkedin.com/in/bo-wan-44a65819a/">Linkedin</a></div>
<div class="menu-item"><a href="./wanbo_cv.pdf" download="wanbo_cv.pdf">CV</a></div>
</td>

<td id="layout-content">
  <div id="toptitle">
  <h1>Wan, Bo (万博) </h1>
</div>
<table class="imgtable"><tr><td>
  <a href="https://bobwan1995.github.io/"><img src="pic.jpg" alt="alt text" width="150px" height="150px" /></a>&nbsp;</td>
<td align="left"><p>Ph.D. candidate,<br />
  PSI, ESAT, <br />
  KU Leuven, <br />
  Belgium <br />
E-mail: <a href="mailto:bwan@esat.kuleuven.be">bwan@esat.kuleuven.be</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I am currently a last year Ph.D. student supervised by Prof. <a href="https://homes.esat.kuleuven.be/~tuytelaa/">Tinne Tuytelaars</a> at KU Leuven, Belgium. 
  Before that, I received the B.S. degree from the Beijing University of Posts and Telecommunications, in 2017, and the M.S. degree from ShanghaiTech University, in 2020.
  I also obtained a double bachelor's degree in Economics from Peking University in 2017.
  Currently, my main research interests focus on machine learning, especially on: </p>
<ul>
<li><p>Vision-Language Pretraining and Understanding</p>
</li>
<li><p>Unsupervised and Weakly-supervised Learning</p>
</li>
<li><p>Text to Image and Video Generation</p>
</li>
</ul>

<h2>Internship</h2>
<p>Student Researcher @ DeepMind, 7.2023-12.2023</p>
<ul>
<li><p>Work on large-scale location-aware vision-language pretraining.</p>
</li>
</ul>

<p>Student Researcher @ Google Brain, 10.2022-2.2023</p>
<ul>
<li><p>Explore a encoder-decoder trasnformer structure for vision-language multitasking.</p>
</li>
</ul>

<p>Research Intern @ Tencent AI Lab, 08.2020-10.2020</p>
<ul>
<li><p>Concentrate on human-centric video understanding.</p>
</li>
</ul>

<p>Algorithm Intern @ Microsoft, 03.2017-06.2017</p>
<ul>
<li><p>Develop algorithms for Bing Search Question Answering system in Chinese.</p>
</li>
</ul>

<h2>Publications </h2>
<ul>
<!-- <ol> -->
<li><p><b>B. Wan</b>, M. Tschannen, Y. Xian, F. Pavetic, I. Alabdulmohsin, X. Wang, A.S. Pinto, A. Steiner, L. Beyer, X. Zhai, "LocCa: Visual Pretraining with Location-aware Captioners", <i>Arxiv</i>, 2024. [<a href="https://arxiv.org/abs/2403.19596">pdf</a>]</p>
</li>
<li><p>M. Li*, <b>B. Wan*</b>, S. Moens, T. Tuytelaars, "Animate Your Motion: Turning Still Images into Dynamic Videos", <i>Arxiv</i>, 2024. [<a href="https://arxiv.org/abs/2403.10179">pdf</a>]</p>
</li>
<li><p>H. Diao, <b>B. Wan</b>, Y. Zhang, X. Jia, H. Lu, L. Chen, "UniPT: Universal Parallel Tuning for Transfer Learning with Efficient Parameter and Memory Exploitation", <i>CVPR</i>, 2024. [<a href="https://arxiv.org/abs/2308.14316">pdf</a>]</p>
</li>
<li><p><b>B. Wan</b>, T. Tuytelaars, "Exploiting CLIP for Zero-shot HOI Detection Requires Knowledge Distillation at Multiple Levels", <i>WACV</i>, 2024. [<a href="https://openaccess.thecvf.com/content/WACV2024/papers/Wan_Exploiting_CLIP_for_Zero-Shot_HOI_Detection_Requires_Knowledge_Distillation_at_WACV_2024_paper.pdf">pdf</a>]</p>
</li>
<li><p><b>B. Wan</b>*, Y. Liu*, D. Zhou, T. Tuytelaars, X. He, "Weakly-supervised HOI Detection via Prior-guided Bi-level Representation Learning", <i>ICLR</i>, 2023. [<a href="https://arxiv.org/abs/2303.01313">pdf</a>]</p>
</li>
<li><p>L. Beyer*, <b>B. Wan*</b>, G. Madan*, F. Pavetic*, A. Steiner*, A. Kolesnikov, A.S. Pinto, E. Bugliarello, X. Wang, Q. Yu, L. Chen, X. Zhai*, "A Study of Autoregressive Decoders for Multi-Tasking in Computer Vision", <i>Arxiv</i>, 2023. [<a href="https://arxiv.org/abs/2303.17376">pdf</a>]</p>
</li>
<li><p><b>B. Wan</b>, W. Han, Z. Zheng, and T. Tuytelaars, "Unsupervised Vision-Language Grammar Induction with Shared Structure Modeling", <i>ICLR <b style="color: red;">Oral</b></i>, 2022. [<a href="https://openreview.net/forum?id=N0n_QyQ5lBF">pdf</a>]</p>
</li>
<li><p>Y. Liu*, <b>B. Wan</b>*, L. Ma, and X. He, "Relation-aware Instance Refinement for Weakly Supervised Visual Grounding", <i>CVPR</i>, 2021. [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Relation-aware_Instance_Refinement_for_Weakly_Supervised_Visual_Grounding_CVPR_2021_paper.pdf">pdf</a>][<a href="https://github.com/youngfly11/ReIRWeaklyGrounding.pytorch.git">code</a>]</p>
</li>
<li><p>R. Li, S. Zhang, <b>B. Wan</b>, and X. He, "Bipartite graph network with adaptive message passing for unbiased scene graph generation", <i>CVPR</i>, 2021. [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Bipartite_Graph_Network_With_Adaptive_Message_Passing_for_Unbiased_Scene_CVPR_2021_paper.pdf">pdf</a>][<a href="https://github.com/Scarecrow0/BGNN-SGG">code</a>]</p>
</li>
<li><p>Q. He, D. Zhou, <b>B. Wan</b>, and X. He, "Single Image 3D Object Estimation with Primitive Graph Networks", <i>ACMMM</i>, 2021. [<a href="https://arxiv.org/pdf/2109.04153.pdf">pdf</a>]</p>
</li>
<li><p>Y. Liu*, <b>B. Wan</b>*, L. Ma, and X. He, "Learning cross-modal context graph for visual grounding", <i>AAAI</i>, 2020. [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/6833/6687">pdf</a>][<a href="https://github.com/youngfly11/LCMCG-PyTorch">code</a>]</p>
</li>
<li><p><b>B. Wan</b>*, D. Zhou*, Y. Liu, R. Li, and X. He, "Pose-aware multi-level feature network for human object interaction detection", <i>ICCV <b style="color: red;">Oral</b></i>, 2019. [<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Wan_Pose-Aware_Multi-Level_Feature_Network_for_Human_Object_Interaction_Detection_ICCV_2019_paper.pdf">pdf</a>][<a href="https://github.com/bobwan1995/PMFNet">code</a>]</p>
</li>
<!-- </ol> -->
</ul>
<p><b>Note</b>: * indicates equal contribution. Full list of publications in <a href="https://scholar.google.com/citations?user=_7KkpE4AAAAJ&hl=en">Google Scholar</a>.</p>

<h2>Academic service</h2>
<p>Reviewer for TPAMI, ICML, ICLR, NeurIPS, CVPR, ICCV, ECCV, WACV, ICIP</p>


</td>
</tr>
</table>
</body>
</html>
